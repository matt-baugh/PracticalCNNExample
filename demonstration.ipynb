{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Machine Learning to Image classification - Demo\n",
    "\n",
    "\n",
    "Running this notebook yourself:\n",
    "* Dependencies - need to install first\n",
    "    * Sklearn    - https://scikit-learn.org/stable/install.html\n",
    "    * Jupyterlab - https://jupyter.org/install\n",
    "    * Numpy      - https://numpy.org/install/\n",
    "    * Pytorch & Torchvision    - https://pytorch.org/get-started/locally/\n",
    "* Testing\n",
    "    * For linux, run `jupyter-lab` on a terminal in the same directory as this notebook\n",
    "        * `jupyter-notebook` should also work.\n",
    "    * For windows, running `jupyter-lab` from the command prompt should work but I have not tested this. \n",
    "        * See https://jupyter.org/install for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and visualise data.\n",
    "\n",
    "The data used here is the Fashion-MNIST dataset, more information about the dataset is in this paper:\n",
    "\n",
    "[1] Han Xiao, Kashif Rasul, Roland Vollgraf. Fashion-MNIST: A novel image dataset for benchmarking machine learning algorithms. [arXiv:1708.07747](https://arxiv.org/abs/1708.07747)\n",
    "\n",
    "The dataset is prepared in a similar way to MNIST (handwritten text dataset) but here the images are of items of clothing. The images are of size 28x28 pixels, and are divided into 10 classes:\n",
    "0. T-shirt\n",
    "1. Trousers\n",
    "2. Pullover\n",
    "3. Dress\n",
    "4. Coat\n",
    "5. Sandal\n",
    "6. Shirt\n",
    "7. Sneaker\n",
    "8. Bag\n",
    "9. Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_set = torchvision.datasets.FashionMNIST(root='.', download=True, train=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_image = np.array(train_set.data)\n",
    "train_label = np.array(train_set.targets)\n",
    "class_name = train_set.classes\n",
    "\n",
    "# Load testing data\n",
    "test_set = torchvision.datasets.FashionMNIST(root='.', download=True, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "test_image = np.array(test_set.data)\n",
    "test_label = np.array(test_set.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the balance between training and testing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training input dimensions: \", train_image.shape)\n",
    "print(\"training label dimensions: \", train_label.shape)\n",
    "print(\"test input dimensions: \", test_image.shape)\n",
    "print(\"test label dimensions: \", test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does our data actually look like?\n",
    "\n",
    "Each row shows 10 samples for one class (row 1 shows 10 `T-shirt` images, row 2 shows 10 `Trousers` images, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_images = [[] for _ in range(10)]\n",
    "\n",
    "for i in range(len(train_label)):\n",
    "    grouped_images[train_label[i]].append(train_image[i])\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for g in range(10):\n",
    "    for i in range(10):\n",
    "        plt.subplot(10, 10, g*10 + i + 1)\n",
    "        plt.imshow(grouped_images[g][i], cmap='gray', vmin=0, vmax=255)\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is our dataset balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(F\"Size of class {i}: {len(grouped_images[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply machine learning to the problem\n",
    "\n",
    "### Build the CNN\n",
    "\n",
    "Our network architecture is based on LeNet (shown below), which has a number of convolutional layers followed by a few fully connected layers.\n",
    "\n",
    "![](lenet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, l1=6, l2=16, l3=120, l4=84):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Take single grayscale image, make 6 feature maps with convolutions\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=l1, kernel_size=5, padding=2)\n",
    "        # Pool 28x28 outputs to be 14x14\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Take 6 14x14 pools, make 16 10x10 feature maps\n",
    "        self.conv3 = nn.Conv2d(in_channels=l1, out_channels=l2, kernel_size=5)\n",
    "        # Pool 10x10 layers to be 5x5\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Use 5x5 convolution to make 16 5x5 featuremaps into neurons\n",
    "        self.conv5 = nn.Conv2d(in_channels=l2, out_channels=l3, kernel_size=5)\n",
    "        \n",
    "        self.fc6 = nn.Linear(l3, l4)\n",
    "        \n",
    "        self.fc7 = nn.Linear(l4, 10)\n",
    "        \n",
    "        self.arch = F\"leaky_relu_var_params_({l1}, {l2}, {l3}, {l4})\"\n",
    "        self.version = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # (1, 28, 28) to (6, 28, 28)\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        #(6, 28, 28) to (6, 14, 14)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # (6, 14, 14) to (16, 10, 10)\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        # (16, 10, 10) to (16, 5, 5)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        # (16, 5, 5) to (120, 1, 1)\n",
    "        x = self.conv5(x)\n",
    "        \n",
    "        \n",
    "        # Reshape data to fit fully connected layer\n",
    "        # (120, 1, 1) to (1, 120)\n",
    "        x = x.view(-1, 120)\n",
    "        \n",
    "        # (1, 120) to (1, 84)\n",
    "        x = F.leaky_relu(self.fc6(x))\n",
    "        \n",
    "        # (1, 84) to (1, 10)\n",
    "        x = self.fc7(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hyperparameters to be used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set MAX_EPOCHs here, but actually stops by evaluating performance on validation set (early stopping)\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Optimiser is declared inside train_with_early_stop\n",
    "# As I'm using the Adam optimiser, which has an adaptive learing rate, I do not set the learning rate myself\n",
    "\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "First define helper functions for testing and evaluating the network. Then define a function to train the model.\n",
    "\n",
    "At each iteration, get a random batch of images and labels from train_image and train_label (the DataLoader does this for us), feed into the network model and perform gradient descent (done by `optimiser.step`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_cnn(cnn, loader):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs, labels = data\n",
    "            outputs = cnn(inputs)\n",
    "            preds = torch.argmax(outputs.data, 1)\n",
    "            predictions += preds\n",
    "    return np.array(predictions)\n",
    "\n",
    "def eval_acc_cnn(cnn, loader):\n",
    "    preds = test_cnn(cnn, loader)\n",
    "    r_labels = []\n",
    "    for data in loader:\n",
    "        _, ls = data\n",
    "        r_labels += ls\n",
    "        \n",
    "    r_labels = np.array(r_labels)\n",
    "    correct = (preds == r_labels).sum().item()\n",
    "    return 100 * correct / len(r_labels)\n",
    "\n",
    "def train_with_early_stop(tr_set, val_set, new_net, patience=6):\n",
    "\n",
    "    optimiser = optim.Adam(net.parameters())\n",
    "    \n",
    "    t_l = torch.utils.data.DataLoader(tr_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    v_l = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    iterations_without_increase = 0\n",
    "    best_dict = new_net.state_dict()\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        end_training = False\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(t_l, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Forward progagation\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss_val = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backward propagation\n",
    "            loss_val.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimiser.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss_val.item()\n",
    "            if i % 1000 == 999:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "                # Check for accuracy change\n",
    "                val_acc = eval_acc_cnn(new_net, v_l)\n",
    "                print(F'Val acc: {val_acc}')\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_dict = new_net.state_dict()\n",
    "                    iterations_without_increase = 0\n",
    "                else:\n",
    "                    iterations_without_increase += 1\n",
    "                    if iterations_without_increase >= patience:\n",
    "                        print('Training ended')\n",
    "                        end_training = True\n",
    "                        break\n",
    "                print()\n",
    "        if end_training:\n",
    "            break\n",
    "    new_net.load_state_dict(best_dict)\n",
    "    return new_net, best_val_acc\n",
    "\n",
    "\n",
    "net = FashionCNN()\n",
    "\n",
    "train_sub_set, val_sub_set = torch.utils.data.random_split(train_set, [54000, 6000])\n",
    "\n",
    "start_train = time.time()\n",
    "print(\"Training starting\")\n",
    "net, val_acc = train_with_early_stop(train_sub_set, val_sub_set, net)\n",
    "end_train = time.time()\n",
    "\n",
    "print(F\"Training took {end_train-start_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the network on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False)\n",
    "\n",
    "\n",
    "start_test = time.time()\n",
    "# defined in 2.3\n",
    "all_preds = test_cnn(net, test_loader)\n",
    "\n",
    "end_test = time.time()\n",
    "print(F'Testing took {end_test - start_test} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the accuracy of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = np.array(test_loader.dataset.targets)\n",
    "\n",
    "correct = (all_preds == labels).sum().item()\n",
    "\n",
    "print('Accuracy on test set %.2f %%' % (100 * correct / len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the performance by looking at the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = metrics.confusion_matrix(labels, all_preds)\n",
    "print(conf_matrix)\n",
    "\n",
    "ConfusionMatrixDisplay(conf_matrix, class_name).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the network out on real date\n",
    "\n",
    "I've taken 3 pictures of my own clothes, which fit into the classes the network was trained on. The pictures are formatted in roughly the same way as the training data.\n",
    "\n",
    "### Display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_t_shirt = plt.imread(\"real_images/t_shirt_scaled.JPG\")\n",
    "my_trainer = plt.imread(\"real_images/trainer_scaled.JPG\")\n",
    "my_trousers = plt.imread(\"real_images/trousers_scaled.JPG\")\n",
    "\n",
    "fig, axis = plt.subplots(1, 3)\n",
    "\n",
    "axis[0].imshow(my_t_shirt, cmap='gray', vmin=0, vmax=255)\n",
    "axis[0].set_axis_off()\n",
    "axis[0].set_title(\"My T-Shirt\")\n",
    "\n",
    "axis[1].imshow(my_trainer, cmap='gray', vmin=0, vmax=255)\n",
    "axis[1].set_axis_off()\n",
    "axis[1].set_title(\"My Trainer\")\n",
    "\n",
    "axis[2].imshow(my_trousers, cmap='gray', vmin=0, vmax=255)\n",
    "axis[2].set_axis_off()\n",
    "axis[2].set_title(\"My Trousers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out the network on the real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "real_images_tensor = torch.FloatTensor([[my_t_shirt], [my_trainer], [my_trousers]])\n",
    "real_images_outputs = net(real_images_tensor)\n",
    "\n",
    "real_images_predictions = torch.argmax(real_images_outputs, 1)\n",
    "\n",
    "print(F\"T-Shirt prediction: {class_name[real_images_predictions[0]]} (class {real_images_predictions[0]})\")\n",
    "print(F\"Trainer prediction: {class_name[real_images_predictions[1]]} (class {real_images_predictions[1]})\")\n",
    "print(F\"Trousers prediction: {class_name[real_images_predictions[2]]} (class {real_images_predictions[2]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
